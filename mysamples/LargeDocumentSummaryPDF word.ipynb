{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "# from langchain.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"DEFAULT_EMBED_BATCH_SIZE\"] = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import TextLoader\n",
    "# data = TextLoader('output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original:\t305882 characters\n",
      "Length of final:\t123016 characters\n",
      "Percent Reduction:\t60%\n"
     ]
    }
   ],
   "source": [
    "import webvtt\n",
    "\n",
    "vtt = webvtt.read('data/Equitable_Microsoft-mtc.vtt')\n",
    "outfile = 'output.txt'\n",
    "transcript = \"\"\n",
    "last_speaker = None\n",
    "\n",
    "for line in vtt:\n",
    "    if line.text:\n",
    "        if line.identifier and '-' in line.identifier:\n",
    "            speaker = line.identifier.split('/')[1].split('-')[0]\n",
    "            if last_speaker != speaker:\n",
    "                transcript += '\\n' + speaker + ': '\n",
    "            transcript += ' ' + line.text.strip()\n",
    "            last_speaker = speaker\n",
    "\n",
    "with open(outfile, 'w') as f:\n",
    "    f.write(transcript)\n",
    "\n",
    "print(\n",
    "    f'Length of original:\\t{len(vtt.content)} characters\\nLength of final:\\t{len(transcript)} characters\\nPercent Reduction:\\t{100 - len(transcript)*100/len(vtt.content):.0f}%'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# docs = text_splitter.split_documents(transcript)\n",
    "splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = splitter.split_text(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks:\",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\n24:  Think works.\\n175:  So fabric where we announced\\nduring our our build event last month. So so fabric is not\\nsomething that you know, this is we started like one year ago or\\nsomething. This this product, which is making for loss or 34\\nyears and it's it was our reason like we're back, then, that we\\nwant some sort of unified platform and this slide shows\\nthat you know every every chief data officer in every\\nenterprise.\\n180:  They do have these kind of\\nchallenges and that one is that, you know, there are so many\\nprojects over there and every system need different class of\\nproducts and then product come from multiple vendors and also\\nthere is you know issue of integrating at the scale across\\nproduct is really, really complex.\\n227:  So you can you can buy, make the\\nbest of the three products from different vendor, but if they\\nthey can't talk to each other then it's it's really really you\\nknow not productive for any kind of business.\\n265:  And this is, you know this or\\nhere this is some sort of like you know sample architecture\\nacross different enterprises, you see the architecture over\\nhere, there are different component over there.\\n329:  So if you have different\\ncomponent from different vendor then you're architecture becomes\\nso complex with the time that you don't know like you know\\nwhat are the different products we are using, how data is\\nflowing between them or is there are there different copies of\\ndata across all these systems.\\n364:  The other integration one just\\nto confirm, is if we were using Sentinel as a seam, how much is\\nper view integrated with or fabric integrated with it?\\n369:  It's sending them.\\n375:  There may be an.\\n378:  Again, I'm.\\n394:  I'm channeling Della Dev, but\\nthat would be a a question we would ask right?\\n415:  Cause we talked about these and\\nthe access to data as part of indicators of compromise.\\n428:  How much of that is integrated\\ninto Microsoft Scene Toolkit?\\n430:  What?\\n442:  I've seen with heard you.\\n465:  It's mostly a tight integration\\nwith defender for cloud, but in terms of Sentinel, I haven't\\nworked with any security teams for that.\\n471:  Yes, I have deployed.\\n475:  Right now we do not.\\n486:  OK, we do have defender for\\ncloud deployed.\\n488:  OK.\\n490:  So.\\n498:  So no, so I'm I'm still in that.\\n515:  I mean, when you say it's a\\ntarget architecture, where is fabric setting?\\n535:  Yeah, this is how we are trying\\nto like show the pain points that every customer has.\\n545:  Ohh OK, because it says target\\narchitecture.\\n563:  I thought it's like you're\\nshowing where there is overly detailed version.\\n565:  OK.\\n567:  Yeah.\\n595:  So we are saying that, you know\\nthis is, you know customer right now they do have this kind of\\nagreed, yeah, they OK different system.\\n619:  And this is, you know, another\\nexample or here, but quickly I I'll jump into the fabric.\\n687:  So then things that in Microsoft\\nwe do have all these, all these product and and they're all\\nthese analytics system they do have very predictable pattern\\nover there.\\n689:  And for us, Microsoft, good\\nthing is that we do have product for data integration, data\\nengineering, data warehousing, real time, data science and\\nbusiness intelligence.\\n692:  And then we do our data lake and\\ngovernance.\\n712:  So that is the silver lining\\nthat we do have all these, all these product within Microsoft.\\n721:  It means we can do something\\nwith this product.\\n743:  Maybe you can combine them in in\\nin in one product or there can be some seamless experience.\\n750:  We we can provide to our our\\ncustomer.\\n804:  So even after that, you know\\nit's still, you know, as you see over here, we do different\\nproduct and customer always struggle that hey you know data\\nfactory then you know then power BI snaps and you know there's\\nsnaps park over there.\\n869:  So still customer feel that you\\nknow we do have so many product and then you know they\",\n",
       " \"\\n750:  We we can provide to our our\\ncustomer.\\n804:  So even after that, you know\\nit's still, you know, as you see over here, we do different\\nproduct and customer always struggle that hey you know data\\nfactory then you know then power BI snaps and you know there's\\nsnaps park over there.\\n869:  So still customer feel that you\\nknow we do have so many product and then you know they they they\\nwant some sort of like seamless experience they can go to one UI\\nor one product and they can use all these computing and show it\\nthere and they can have you know all these things and talking to\\neach other.\\n887:  So that's, that's where, you\\nknow, Microsoft Fabric come into the picture.\\n904:  So this is, you know, the\\nproject started at at we called it Project Trident.\\n919:  So now name is the Microsoft\\nFabric we announced at the build.\\n947:  So what we did in the in, in, in\\nMicrosoft Fabric, we took all our product and we made you know\\n11 product out of it.\\n972:  So that you know, use the one\\nproduct, but all these compute and then the data format\\neverything.\\n998:  The all these images they can\\ntalk to each other, they will work on top of the one copy of\\nthe data.\\n1030:  So that's the whole concept of\\nover here is that you know you have the one copy of data and\\nall our engines will natively talk to that data.\\n1082:  So earlier you know for example\\nPower BI pleased to have some internal proprietary format, for\\nexample the power BI is pointing to your data, then it will pull\\nthat data into power BI internal format or internal engine and it\\nwill convert that format and then it will do reporting.\\n1114:  So what we did behind the scene\\nis that for all these product we change the internal format to\\nsupport the Delta format.\\n1155:  It means when power BI is\\nworking with the data, it's not making a copy of data, it's\\ngoing directly against the one leg and it's talking with the\\nwith the Delta format directly over there.\\n1164:  It means it's super, super fast\\nover there.\\n1191:  So we change the internal format\\nor internal, you know, proprietary format to support\\nthat delta files natively in all this product.\\n1209:  And what is that format so that\\nis DD market format.\\n1226:  The data bricks has created a\\nwrapper on top of park.\\n1228:  Call it delta.\\n1239:  OK. That's what they're talking\\nnow.\\n1248:  That is becoming almost\\nindustries industries, right?\\n1281:  Yeah, so, so, but but are you\\njust wanted to make sure that when you say all these\\ncomponents are you saying that fabric is gonna replace all\\nthose components?\\n1288:  So yeah.\\n1301:  So Perry, the all these\\ncomponents will be replaced by fabric.\\n1337:  But right now or in the future\\nalso, what will happen, for example, kusto, so you can still\\nuse the kusto, but it will be inside of fabric itself.\\n1346:  It will negatively available\\ninside the fabric.\\n1365:  For example, right now if you\\nwant to use the kusto or power BI, it will read your data.\\n1404:  It will make copy of it and then\\ndo the processing but with the fabric because this for the the\\nDelta format natively and they are available within the fabric\\nitself.\\n1432:  It means if you have data or\\nthere in one leg then you can simply use the kusto Azure know\\nthe power BI snaps everything.\\n1466:  It means you have one copy of\\ndata and you do have one UI and inside that UI you can use any\\nof the computing then easily without without changing\\nanything.\\n1469:  So.\\n1578:  So I just wanna clarify, when\\nyou say 1 lake, are you it's it's any like a pocket format\\nfiles right or does it have to be on a Microsoft one leg a\\nplatform it it it's one leg is is we call it you know our our\\nnew sass leg sassman new software as service leg but the\\nformat is open format, it's delta format I understand but\\nI'm just trying to\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0],docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Python version mismatch: module was compiled for Python 3.6, but the interpreter version is incompatible: 3.10.11 (main, Apr  5 2023, 14:15:30) [GCC 7.5.0].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m persist_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m docsearch \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m      3\u001b[0m     docs, \n\u001b[1;32m      4\u001b[0m     embeddings,\n\u001b[1;32m      5\u001b[0m     persist_directory \u001b[39m=\u001b[39;49m persist_directory,\n\u001b[1;32m      6\u001b[0m     metadatas\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39msource\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m-pl\u001b[39;49m\u001b[39m\"\u001b[39;49m} \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(docs))]\n\u001b[1;32m      7\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:383\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    355\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    365\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    366\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[1;32m    368\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    384\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    385\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    386\u001b[0m         persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    387\u001b[0m         client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    388\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    390\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:89\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[39mif\u001b[39;00m persist_directory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_settings \u001b[39m=\u001b[39m chromadb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mSettings(\n\u001b[1;32m     86\u001b[0m                 chroma_db_impl\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mduckdb+parquet\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m                 persist_directory\u001b[39m=\u001b[39mpersist_directory,\n\u001b[1;32m     88\u001b[0m             )\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m chromadb\u001b[39m.\u001b[39;49mClient(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client_settings)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m     92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persist_directory \u001b[39m=\u001b[39m persist_directory\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/__init__.py:31\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     28\u001b[0m system \u001b[39m=\u001b[39m System(settings)\n\u001b[1;32m     30\u001b[0m telemetry_client \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39minstance(Telemetry)\n\u001b[0;32m---> 31\u001b[0m api \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39;49minstance(API)\n\u001b[1;32m     33\u001b[0m system\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     35\u001b[0m \u001b[39m# Submit event for client start\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/config.py:160\u001b[0m, in \u001b[0;36mSystem.instance\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m get_class(fqn, \u001b[39mtype\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instances:\n\u001b[0;32m--> 160\u001b[0m     impl \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instances[\u001b[39mtype\u001b[39m] \u001b[39m=\u001b[39m impl\n\u001b[1;32m    162\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_running:\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/api/local.py:61\u001b[0m, in \u001b[0;36mLocalAPI.__init__\u001b[0;34m(self, system)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, system: System):\n\u001b[1;32m     60\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(system)\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_db \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequire(DB)\n\u001b[1;32m     62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_telemetry_client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire(Telemetry)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/config.py:106\u001b[0m, in \u001b[0;36mComponent.require\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequire\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m: Type[T]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a Component instance of the given type, and register as a dependency of\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    that instance.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     inst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_system\u001b[39m.\u001b[39;49minstance(\u001b[39mtype\u001b[39;49m)\n\u001b[1;32m    107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dependencies\u001b[39m.\u001b[39madd(inst)\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m inst\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/config.py:157\u001b[0m, in \u001b[0;36mSystem.instance\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    155\u001b[0m     key \u001b[39m=\u001b[39m _abstract_type_keys[type_fqn]\n\u001b[1;32m    156\u001b[0m     fqn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mrequire(key)\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m get_class(fqn, \u001b[39mtype\u001b[39;49m)\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instances:\n\u001b[1;32m    160\u001b[0m     impl \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/config.py:203\u001b[0m, in \u001b[0;36mget_class\u001b[0;34m(fqn, type)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Given a fully qualifed class name, import the module and return the class\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m module_name, class_name \u001b[39m=\u001b[39m fqn\u001b[39m.\u001b[39mrsplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(module_name)\n\u001b[1;32m    204\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, class_name)\n\u001b[1;32m    205\u001b[0m \u001b[39mreturn\u001b[39;00m cast(Type[C], \u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/db/duckdb.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m System\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Documents, Embeddings, IDs, Metadatas\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclickhouse\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     Clickhouse,\n\u001b[1;32m      6\u001b[0m     db_array_schema_to_clickhouse_schema,\n\u001b[1;32m      7\u001b[0m     EMBEDDING_TABLE_SCHEMA,\n\u001b[1;32m      8\u001b[0m     db_schema_to_keys,\n\u001b[1;32m      9\u001b[0m     COLLECTION_TABLE_SCHEMA,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List, Optional, Sequence\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/db/clickhouse.py:11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     Documents,\n\u001b[1;32m      4\u001b[0m     Embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     WhereDocument,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdb\u001b[39;00m \u001b[39mimport\u001b[39;00m DB\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindex\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhnswlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Hnswlib, delete_all_indexes\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39muuid\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/chromadb/db/index/hnswlib.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, List, Optional, Set, Tuple, Union, cast\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Embeddings, IndexMetadata\n\u001b[0;32m----> 7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhnswlib\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Settings\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindex\u001b[39;00m \u001b[39mimport\u001b[39;00m Index\n",
      "\u001b[0;31mImportError\u001b[0m: Python version mismatch: module was compiled for Python 3.6, but the interpreter version is incompatible: 3.10.11 (main, Apr  5 2023, 14:15:30) [GCC 7.5.0]."
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "docsearch = Chroma.from_texts(\n",
    "    docs, \n",
    "    embeddings,\n",
    "    persist_directory = persist_directory,\n",
    "    metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(docs))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextLoader' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text_splitter \u001b[39m=\u001b[39m CharacterTextSplitter(chunk_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, chunk_overlap\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39;49msplit_text(data)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/text_splitter.py:215\u001b[0m, in \u001b[0;36mCharacterTextSplitter.split_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m# First we naively split the large input into a bunch of smaller ones.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_separator:\n\u001b[0;32m--> 215\u001b[0m     splits \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39;49msplit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_separator)\n\u001b[1;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     splits \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextLoader' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msysconfig\u001b[39;00m\n\u001b[1;32m      3\u001b[0m paths \u001b[39m=\u001b[39m sysconfig\u001b[39m.\u001b[39mget_paths()\n\u001b[0;32m----> 4\u001b[0m cache_dir \u001b[39m=\u001b[39m paths[\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCache Directory: \u001b[39m\u001b[39m{\u001b[39;00mcache_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "import sysconfig\n",
    "\n",
    "paths = sysconfig.get_paths()\n",
    "cache_dir = paths['']\n",
    "print(f\"Cache Directory: {cache_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(engine=\"davinci\",temperature=0)\n",
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m last_speaker \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m vtt:\n\u001b[0;32m----> 7\u001b[0m     speaker \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39;49mlines[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39mv \u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m last_speaker \u001b[39m!=\u001b[39m speaker:\n\u001b[1;32m      9\u001b[0m         lines\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mspeaker \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import webvtt\n",
    "vtt = webvtt.read('data/Equitable_Microsoft-mtc.vtt')\n",
    "transcript = \"\"\n",
    "lines = []\n",
    "last_speaker = None\n",
    "for line in vtt:\n",
    "    speaker = line.lines[0].split('>')[0].split('v ')[1]\n",
    "    if last_speaker != speaker:\n",
    "        lines.append('\\n'+speaker + ': ')\n",
    "    lines.extend(line.text.strip().splitlines())\n",
    "    last_speaker = speaker\n",
    "previous = None\n",
    "for line in lines:\n",
    "    if line == previous:\n",
    "        continue\n",
    "    transcript += f\" {line.strip()}\"\n",
    "    previous = line\n",
    "with open(outfile, 'w') as f:\n",
    "    f.write(transcript)\n",
    "print(f'Length of original:\\t{len(vtt.content)} characters\\nLength of final:\\t{len(transcript)} characters\\nPercent Reduction:\\t{100 - len(transcript)*100/len(vtt.content):.0f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original:\t305882 characters\n",
      "Length of final:\t123016 characters\n",
      "Percent Reduction:\t60%\n"
     ]
    }
   ],
   "source": [
    "import webvtt\n",
    "\n",
    "vtt = webvtt.read('data/Equitable_Microsoft-mtc.vtt')\n",
    "outfile = 'output.txt'\n",
    "transcript = \"\"\n",
    "last_speaker = None\n",
    "\n",
    "for line in vtt:\n",
    "    if line.text:\n",
    "        if line.identifier and '-' in line.identifier:\n",
    "            speaker = line.identifier.split('/')[1].split('-')[0]\n",
    "            if last_speaker != speaker:\n",
    "                transcript += '\\n' + speaker + ': '\n",
    "            transcript += ' ' + line.text.strip()\n",
    "            last_speaker = speaker\n",
    "\n",
    "with open(outfile, 'w') as f:\n",
    "    f.write(transcript)\n",
    "\n",
    "print(\n",
    "    f'Length of original:\\t{len(vtt.content)} characters\\nLength of final:\\t{len(transcript)} characters\\nPercent Reduction:\\t{100 - len(transcript)*100/len(vtt.content):.0f}%'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# docs = text_splitter.split_documents(transcript)\n",
    "splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = splitter.split_text(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of chunks:\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mlen\u001b[39m(docs))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks:\",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm=ChatOpenAI(temperature=0.7, engine=\"gpt-4\")\n",
    "# llm=ChatOpenAI(temperature=0.7, engine=\"gpt-4\", max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\n24:  Think works.\\n175:  So fabric where we announced\\nduring our our build event last month. So so fabric is not\\nsomething that you know, this is we started like one year ago or\\nsomething. This this product, which is making for loss or 34\\nyears and it's it was our reason like we're back, then, that we\\nwant some sort of unified platform and this slide shows\\nthat you know every every chief data officer in every\\nenterprise.\\n180:  They do have these kind of\\nchallenges and that one is that, you know, there are so many\\nprojects over there and every system need different class of\\nproducts and then product come from multiple vendors and also\\nthere is you know issue of integrating at the scale across\\nproduct is really, really complex.\\n227:  So you can you can buy, make the\\nbest of the three products from different vendor, but if they\\nthey can't talk to each other then it's it's really really you\\nknow not productive for any kind of business.\\n265:  And this is, you know this or\\nhere this is some sort of like you know sample architecture\\nacross different enterprises, you see the architecture over\\nhere, there are different component over there.\\n329:  So if you have different\\ncomponent from different vendor then you're architecture becomes\\nso complex with the time that you don't know like you know\\nwhat are the different products we are using, how data is\\nflowing between them or is there are there different copies of\\ndata across all these systems.\\n364:  The other integration one just\\nto confirm, is if we were using Sentinel as a seam, how much is\\nper view integrated with or fabric integrated with it?\\n369:  It's sending them.\\n375:  There may be an.\\n378:  Again, I'm.\\n394:  I'm channeling Della Dev, but\\nthat would be a a question we would ask right?\\n415:  Cause we talked about these and\\nthe access to data as part of indicators of compromise.\\n428:  How much of that is integrated\\ninto Microsoft Scene Toolkit?\\n430:  What?\\n442:  I've seen with heard you.\\n465:  It's mostly a tight integration\\nwith defender for cloud, but in terms of Sentinel, I haven't\\nworked with any security teams for that.\\n471:  Yes, I have deployed.\\n475:  Right now we do not.\\n486:  OK, we do have defender for\\ncloud deployed.\\n488:  OK.\\n490:  So.\\n498:  So no, so I'm I'm still in that.\\n515:  I mean, when you say it's a\\ntarget architecture, where is fabric setting?\\n535:  Yeah, this is how we are trying\\nto like show the pain points that every customer has.\\n545:  Ohh OK, because it says target\\narchitecture.\\n563:  I thought it's like you're\\nshowing where there is overly detailed version.\\n565:  OK.\\n567:  Yeah.\\n595:  So we are saying that, you know\\nthis is, you know customer right now they do have this kind of\\nagreed, yeah, they OK different system.\\n619:  And this is, you know, another\\nexample or here, but quickly I I'll jump into the fabric.\\n687:  So then things that in Microsoft\\nwe do have all these, all these product and and they're all\\nthese analytics system they do have very predictable pattern\\nover there.\\n689:  And for us, Microsoft, good\\nthing is that we do have product for data integration, data\\nengineering, data warehousing, real time, data science and\\nbusiness intelligence.\\n692:  And then we do our data lake and\\ngovernance.\\n712:  So that is the silver lining\\nthat we do have all these, all these product within Microsoft.\\n721:  It means we can do something\\nwith this product.\\n743:  Maybe you can combine them in in\\nin in one product or there can be some seamless experience.\\n750:  We we can provide to our our\\ncustomer.\\n804:  So even after that, you know\\nit's still, you know, as you see over here, we do different\\nproduct and customer always struggle that hey you know data\\nfactory then you know then power BI snaps and you know there's\\nsnaps park over there.\\n869:  So still customer feel that you\\nknow we do have so many product and then you know they\",\n",
       " \"\\n750:  We we can provide to our our\\ncustomer.\\n804:  So even after that, you know\\nit's still, you know, as you see over here, we do different\\nproduct and customer always struggle that hey you know data\\nfactory then you know then power BI snaps and you know there's\\nsnaps park over there.\\n869:  So still customer feel that you\\nknow we do have so many product and then you know they they they\\nwant some sort of like seamless experience they can go to one UI\\nor one product and they can use all these computing and show it\\nthere and they can have you know all these things and talking to\\neach other.\\n887:  So that's, that's where, you\\nknow, Microsoft Fabric come into the picture.\\n904:  So this is, you know, the\\nproject started at at we called it Project Trident.\\n919:  So now name is the Microsoft\\nFabric we announced at the build.\\n947:  So what we did in the in, in, in\\nMicrosoft Fabric, we took all our product and we made you know\\n11 product out of it.\\n972:  So that you know, use the one\\nproduct, but all these compute and then the data format\\neverything.\\n998:  The all these images they can\\ntalk to each other, they will work on top of the one copy of\\nthe data.\\n1030:  So that's the whole concept of\\nover here is that you know you have the one copy of data and\\nall our engines will natively talk to that data.\\n1082:  So earlier you know for example\\nPower BI pleased to have some internal proprietary format, for\\nexample the power BI is pointing to your data, then it will pull\\nthat data into power BI internal format or internal engine and it\\nwill convert that format and then it will do reporting.\\n1114:  So what we did behind the scene\\nis that for all these product we change the internal format to\\nsupport the Delta format.\\n1155:  It means when power BI is\\nworking with the data, it's not making a copy of data, it's\\ngoing directly against the one leg and it's talking with the\\nwith the Delta format directly over there.\\n1164:  It means it's super, super fast\\nover there.\\n1191:  So we change the internal format\\nor internal, you know, proprietary format to support\\nthat delta files natively in all this product.\\n1209:  And what is that format so that\\nis DD market format.\\n1226:  The data bricks has created a\\nwrapper on top of park.\\n1228:  Call it delta.\\n1239:  OK. That's what they're talking\\nnow.\\n1248:  That is becoming almost\\nindustries industries, right?\\n1281:  Yeah, so, so, but but are you\\njust wanted to make sure that when you say all these\\ncomponents are you saying that fabric is gonna replace all\\nthose components?\\n1288:  So yeah.\\n1301:  So Perry, the all these\\ncomponents will be replaced by fabric.\\n1337:  But right now or in the future\\nalso, what will happen, for example, kusto, so you can still\\nuse the kusto, but it will be inside of fabric itself.\\n1346:  It will negatively available\\ninside the fabric.\\n1365:  For example, right now if you\\nwant to use the kusto or power BI, it will read your data.\\n1404:  It will make copy of it and then\\ndo the processing but with the fabric because this for the the\\nDelta format natively and they are available within the fabric\\nitself.\\n1432:  It means if you have data or\\nthere in one leg then you can simply use the kusto Azure know\\nthe power BI snaps everything.\\n1466:  It means you have one copy of\\ndata and you do have one UI and inside that UI you can use any\\nof the computing then easily without without changing\\nanything.\\n1469:  So.\\n1578:  So I just wanna clarify, when\\nyou say 1 lake, are you it's it's any like a pocket format\\nfiles right or does it have to be on a Microsoft one leg a\\nplatform it it it's one leg is is we call it you know our our\\nnew sass leg sassman new software as service leg but the\\nformat is open format, it's delta format I understand but\\nI'm just trying to\")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0], docs[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m persist_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m docsearch \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m      3\u001b[0m     docs, \n\u001b[1;32m      4\u001b[0m     embeddings,\n\u001b[1;32m      5\u001b[0m     persist_directory \u001b[39m=\u001b[39m persist_directory,\n\u001b[0;32m----> 6\u001b[0m     metadatas\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m-pl\u001b[39m\u001b[39m\"\u001b[39m} \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "docsearch = Chroma.from_texts(\n",
    "    docs, \n",
    "    embeddings,\n",
    "    persist_directory = persist_directory,\n",
    "    metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(texts))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'TextLoader' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m----> 2\u001b[0m faiss \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39;49mfrom_texts(loader, embeddings)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:426\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    408\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FAISS:\n\u001b[1;32m    409\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \n\u001b[1;32m    411\u001b[0m \u001b[39m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m     embeddings \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    427\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__from(\n\u001b[1;32m    428\u001b[0m         texts,\n\u001b[1;32m    429\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    434\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:297\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:203\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_len_safe_embeddings\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39m, engine: \u001b[39mstr\u001b[39m, chunk_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m--> 203\u001b[0m     embeddings: List[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(texts))]\n\u001b[1;32m    204\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mtiktoken\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'TextLoader' has no len()"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "faiss = FAISS.from_texts(loader, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCreate list of action items from the meeting text below: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m index\u001b[39m.\u001b[39mquery(query)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"Create list of action items from the meeting text below: \"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['Microsoft Fabric was announced during a recent build event and aims to provide a unified platform to address challenges faced by chief data officers in enterprises. These challenges include managing multiple projects, integrating various products from different vendors, and ensuring seamless data flow between systems. Microsoft has products covering data integration, engineering, warehousing, real-time data science, and business intelligence, which can potentially be combined into one product or a seamless experience for customers. Microsoft Fabric intends to offer this streamlined experience, enabling easier management of data and systems for businesses.',\n",
       "  'Microsoft Fabric, previously known as Project Trident, was announced during a recent build event and aims to provide a unified platform to address challenges faced by chief data officers in enterprises. These challenges include managing multiple projects, integrating various products from different vendors, and ensuring seamless data flow between systems. Microsoft has taken their existing products covering data integration, engineering, warehousing, real-time data science, and business intelligence, and consolidated them into 11 products within the Fabric ecosystem. This allows the products to work on top of one copy of data, improving efficiency and communication between systems. Microsoft Fabric has also adopted the Delta format as its native file format, which enables products like Power BI to work directly with the data without making copies or conversions. This makes the platform faster and more efficient for businesses, allowing them to manage their data and systems with ease.'],\n",
       " 'output_text': 'Microsoft Fabric, previously known as Project Trident, was announced during a recent build event and aims to provide a unified platform to address challenges faced by chief data officers in enterprises. These challenges include managing multiple projects, integrating various products from different vendors, and ensuring seamless data flow between systems. Microsoft has taken their existing products covering data integration, engineering, warehousing, real-time data science, and business intelligence, and consolidated them into 11 products within the Fabric ecosystem. This allows the products to work on top of one copy of data, improving efficiency and communication between systems. Microsoft Fabric has also adopted the Delta format as its native file format, which enables products like Power BI to work directly with the data without making copies or conversions. This makes the platform faster and more efficient for businesses, allowing them to manage their data and systems with ease.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Create list of action items from the meeting text below:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "# chain = load_summarize_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=False, map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", return_intermediate_steps=True)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
