{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "# from langchain.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"DEFAULT_EMBED_BATCH_SIZE\"] = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(engine=\"davinci\",temperature=0)\n",
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"data/SparkOfGPT-4.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextSplitter.split_documents() got an unexpected keyword argument 'disallowed_special'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text_splitter \u001b[39m=\u001b[39m CharacterTextSplitter(chunk_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, chunk_overlap\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m docs \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39;49msplit_documents(pages, disallowed_special\u001b[39m=\u001b[39;49m())\n",
      "\u001b[0;31mTypeError\u001b[0m: TextSplitter.split_documents() got an unexpected keyword argument 'disallowed_special'"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages, disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import JSONLoader\n",
    "# loader = JSONLoader(\"data/MedicalRecords.json\", jq_schema='.key[].text')\n",
    "# pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Encountered text corresponding to disallowed special token '<|endofprompt|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endofprompt|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endofprompt|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m faiss_index \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39;49mfrom_documents(docs, OpenAIEmbeddings(chunk_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m docs \u001b[39m=\u001b[39m faiss_index\u001b[39m.\u001b[39msimilarity_search(\u001b[39m\"\u001b[39m\u001b[39mwhat is GPT-4?\u001b[39m\u001b[39m\"\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/vectorstores/base.py:307\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    306\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39;49mmetadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:426\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    408\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FAISS:\n\u001b[1;32m    409\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \n\u001b[1;32m    411\u001b[0m \u001b[39m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m     embeddings \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    427\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__from(\n\u001b[1;32m    428\u001b[0m         texts,\n\u001b[1;32m    429\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    434\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:297\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:221\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m001\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[39m# See: https://github.com/openai/openai-python/issues/418#issuecomment-1525939500\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m token \u001b[39m=\u001b[39m encoding\u001b[39m.\u001b[39;49mencode(\n\u001b[1;32m    222\u001b[0m     text,\n\u001b[1;32m    223\u001b[0m     allowed_special\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallowed_special,\n\u001b[1;32m    224\u001b[0m     disallowed_special\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisallowed_special,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(token), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ctx_length):\n\u001b[1;32m    227\u001b[0m     tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [token[j : j \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ctx_length]]\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/tiktoken/core.py:117\u001b[0m, in \u001b[0;36mEncoding.encode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    115\u001b[0m         disallowed_special \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(disallowed_special)\n\u001b[1;32m    116\u001b[0m     \u001b[39mif\u001b[39;00m match \u001b[39m:=\u001b[39m _special_token_regex(disallowed_special)\u001b[39m.\u001b[39msearch(text):\n\u001b[0;32m--> 117\u001b[0m         raise_disallowed_special_token(match\u001b[39m.\u001b[39;49mgroup())\n\u001b[1;32m    119\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_core_bpe\u001b[39m.\u001b[39mencode(text, allowed_special)\n",
      "File \u001b[0;32m/mnt/c/Users/kapildhanger/OneDrive - Microsoft/Microsoft_Kapil/Azure_learning/openAI/MySamples/.venv/lib/python3.10/site-packages/tiktoken/core.py:351\u001b[0m, in \u001b[0;36mraise_disallowed_special_token\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_disallowed_special_token\u001b[39m(token: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    352\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncountered text corresponding to disallowed special token \u001b[39m\u001b[39m{\u001b[39;00mtoken\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you want this text to be encoded as a special token, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpass it to `allowed_special`, e.g. `allowed_special=\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mtoken\u001b[39m!r}\u001b[39;00m\u001b[39m, ...\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf you want this text to be encoded as normal text, disable the check for this token \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby passing `disallowed_special=(enc.special_tokens_set - \u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mtoken\u001b[39m!r}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m)`.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo disable this check for all special tokens, pass `disallowed_special=()`.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Encountered text corresponding to disallowed special token '<|endofprompt|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endofprompt|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endofprompt|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
     ]
    }
   ],
   "source": [
    "faiss_index = FAISS.from_documents(docs, OpenAIEmbeddings(chunk_size=1))\n",
    "docs = faiss_index.similarity_search(\"what is GPT-4?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm=ChatOpenAI(temperature=0.7, engine=\"gpt-4\")\n",
    "# llm=ChatOpenAI(temperature=0.7, engine=\"gpt-4\", max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, and summarize these journeys using LLMs with techniques like few-shot prompting, prompt-tuning, and fine-tuning. The results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The study also sheds light on the factors impacting the quality of the generated journey names and uncovers the taxonomy of real users\\' journeys on recommendation platforms.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses. The results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses. The results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses. The results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys. The authors propose an infinite concept personalized clustering algorithm and emphasize the importance of granularity, nuance, and safety in generating journey names, ultimately aiming to create more personalized and meaningful user experiences on recommendation platforms.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses. The results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys. The authors emphasize the importance of granularity, nuance, and safety in generating journey names, ultimately aiming to create more personalized and meaningful user experiences on recommendation platforms.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe authors emphasize the importance of granularity, nuance, and safety in generating journey names, ultimately aiming to create more personalized and meaningful user experiences on recommendation platforms. They explore data-efficient techniques like few-shot prompting and prompt-tuning, as well as data-rich end-to-end fine-tuning for aligning LLMs with user journeys. These methods are tested with different volumes of data, and the ideal dataset for this task would involve users annotating and describing their interest journeys in a nuanced and interesting way.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nTo generate journey names with granularity, nuance, and safety, the authors explore data-efficient techniques like few-shot prompting and prompt-tuning, as well as data-rich end-to-end fine-tuning for aligning LLMs with user journeys. They utilize three different data sources: user interviews, user collections, and expert-curated collections, to create a more personalized and meaningful user experience on recommendation platforms. The researchers test these methods with varying data volumes, aiming to achieve an ideal dataset that involves users annotating and describing their interest journeys in a nuanced and interesting way.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nTo generate journey names with granularity, nuance, and safety, the authors explore data-efficient techniques like few-shot prompting and prompt-tuning, as well as data-rich end-to-end fine-tuning for aligning LLMs with user journeys. They utilize three different data sources: user interviews, user collections, and expert-curated collections, to create a more personalized and meaningful user experience on recommendation platforms. The researchers test these methods with varying data volumes, aiming to achieve an ideal dataset that involves users annotating and describing their interest journeys in a nuanced and interesting way. The ICPC algorithm, with a similarity threshold of 0.1, demonstrates its effectiveness in generating coherent journeys of the right granularity when compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThrough a comparison of journey extraction methods, the ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. The algorithm manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThrough a comparison of journey extraction methods, the ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. The algorithm manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys. Testing different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys. Testing different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys. \\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys. \\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.\\n\\nIn an early analysis, the authors demonstrate that the LLM can generate significantly better journey names when it is only given the journey-specific history, further validating the need for their journey extraction component in the journey service. Additionally, they find that journey-aware recommendations significantly improve the user experience, with an average of 1 out of 10 journeys being served under the current recommendation system, compared to 0.253 when the recommender is journey-aware. These results highlight the potential of making recommendations more aware of user interest journeys, ultimately paving the way for a more personalized and engaging user experience on recommendation platforms.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys.\\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.\\n\\nIn an early analysis, the authors demonstrate that the LLM can generate significantly better journey names when it is only given the journey-specific history, further validating the need for their journey extraction component in the journey service. Additionally, they find that journey-aware recommendations significantly improve the user experience, with an average of 1 out of 10 journeys being served under the current recommendation system, compared to 0.253 when the recommender is journey-aware. These results highlight the potential of making recommendations more aware of user interest journeys, ultimately paving the way for a more personalized and engaging user experience on recommendation platforms. The study contributes to the fields of user modeling, context-aware recommendation, and interpretable/transparent user models, emphasizing the value of journey-aware systems in satisfying users\\' real-life interests and aspirations.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys.\\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.\\n\\nIn an early analysis, the authors demonstrate that the LLM can generate significantly better journey names when it is only given the journey-specific history, further validating the need for their journey extraction component in the journey service. Additionally, they find that journey-aware recommendations significantly improve the user experience, with an average of 1 out of 10 journeys being served under the current recommendation system, compared to 0.253 when the recommender is journey-aware. These results highlight the potential of making recommendations more aware of user interest journeys, ultimately paving the way for a more personalized and engaging user experience on recommendation platforms. The study contributes to the fields of user modeling, context-aware recommendation, and interpretable/transparent user models, emphasizing the value of journey-aware systems in satisfying users\\' real-life interests and aspirations. The research also demonstrates the untapped potential of LLMs in the domain of recommender systems and presents a novel approach to leveraging LLMs for deeper user understanding and building novel user experiences that offer more user control.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys.\\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.\\n\\nIn an early analysis, the authors demonstrate that the LLM can generate significantly better journey names when it is only given the journey-specific history, further validating the need for their journey extraction component in the journey service. Additionally, they find that journey-aware recommendations significantly improve the user experience, with an average of 1 out of 10 journeys being served under the current recommendation system, compared to 0.253 when the recommender is journey-aware. These results highlight the potential of making recommendations more aware of user interest journeys, ultimately paving the way for a more personalized and engaging user experience on recommendation platforms. The study contributes to the fields of user modeling, context-aware recommendation, and interpretable/transparent user models, emphasizing the value of journey-aware systems in satisfying users\\' real-life interests and aspirations. The research also demonstrates the untapped potential of LLMs in the domain of recommender systems and presents a novel approach to leveraging LLMs for deeper user understanding and building novel user experiences that offer more user control.',\n",
       "  'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys.\\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.\\n\\nIn an early analysis, the authors demonstrate that the LLM can generate significantly better journey names when it is only given the journey-specific history, further validating the need for their journey extraction component in the journey service. Additionally, they find that journey-aware recommendations significantly improve the user experience, with an average of 1 out of 10 journeys being served under the current recommendation system, compared to 0.253 when the recommender is journey-aware. These results highlight the potential of making recommendations more aware of user interest journeys, ultimately paving the way for a more personalized and engaging user experience on recommendation platforms. The study contributes to the fields of user modeling, context-aware recommendation, and interpretable/transparent user models, emphasizing the value of journey-aware systems in satisfying users\\' real-life interests and aspirations. The research also demonstrates the untapped potential of LLMs in the domain of recommender systems and presents a novel approach to leveraging LLMs for deeper user understanding and building novel user experiences that offer more user control.'],\n",
       " 'output_text': 'This paper explores the potential of large language models (LLMs) in improving personalized user experiences on recommendation platforms. The authors introduce a framework for personalized extraction of \"interest journeys,\" or persistent user interests, needs, and goals, by leveraging personalized clustering from user interaction logs. They propose an infinite concept personalized clustering algorithm (ICPC) that effectively performs online clustering of a user\\'s interaction history based on the salient terms of the comprising items. LLMs are then used to describe these journeys with interpretable and nuanced names through techniques like few-shot prompting, prompt-tuning, and fine-tuning. The study investigates real-life journeys of users, uncovering a taxonomy of valued interest journeys through clustering survey responses.\\n\\nThe results demonstrate the potential of LLMs in providing deeper, more interpretable, and controllable user understanding, paving the way for new user experiences on recommendation platforms that are journey-aware, assistive, and enable frictionless conversation. The research highlights that people value content related to entertainment, learning, and community engagement, with entertainment and learning new skills being the top valued journeys. Additionally, the findings show that users pursue multiple interest journeys concurrently over long periods of time, rely more on explicit actions to find content relevant to their journeys, and that their journeys are nuanced and evolve in a personalized way. This calls for a more user-centric approach in recommendation systems, offering interpretability and control to users in pursuing their interest journeys.\\n\\nThe ICPC algorithm achieves long coherent journeys and is more robust to trivial coherence as obtained by singleton journey clusters. It manages to easily control journey granularity via the similarity threshold and achieves the highest recall compared to baseline methods using co-occurrence-based clusters and multimodal item similarity-based clusters. By utilizing user interviews, user collections, and expert-curated collections, the authors create a more personalized and meaningful user experience on recommendation platforms, confirming the effectiveness of the ICPC algorithm in generating coherent journeys of the right granularity. The journey naming service can provide accurate, nuanced names describing the user interest journeys, such as \"the art of photography\" and \"orgo kart racing,\" illustrating the practical utility of LLMs in reasoning well through user interest journeys.\\n\\nTesting different prompting techniques, the study finds that prompt-tuning on small high-quality data outperforms few-shot prompting and that fine-tuning offers better in-domain performance, while prompt-tuning has better generalization capability. The effect of model size and architecture is also explored, revealing that LaMDA models achieve the best performance in certain conditions, while instruction-tuned models show potential for better few-shot prompting. Further analysis shows that expertly curated collection names provide higher quality data for learning the prompt compared to user-provided names, suggesting the potential of mixed methods for enabling LLMs to accurately describe user interests. The study also finds that including more journey items results in better name generation performance. Finally, the research emphasizes the importance of high-quality prompt tuning data and the usefulness of item titles as the most informative feature for constructing prompts.\\n\\nIn an early analysis, the authors demonstrate that the LLM can generate significantly better journey names when it is only given the journey-specific history, further validating the need for their journey extraction component in the journey service. Additionally, they find that journey-aware recommendations significantly improve the user experience, with an average of 1 out of 10 journeys being served under the current recommendation system, compared to 0.253 when the recommender is journey-aware. These results highlight the potential of making recommendations more aware of user interest journeys, ultimately paving the way for a more personalized and engaging user experience on recommendation platforms. The study contributes to the fields of user modeling, context-aware recommendation, and interpretable/transparent user models, emphasizing the value of journey-aware systems in satisfying users\\' real-life interests and aspirations. The research also demonstrates the untapped potential of LLMs in the domain of recommender systems and presents a novel approach to leveraging LLMs for deeper user understanding and building novel user experiences that offer more user control.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "# chain = load_summarize_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=False, map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", return_intermediate_steps=True)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
